{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea33b46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 4 messages into Postgres.\n",
      "Inserted 2 messages into Postgres.\n",
      "Inserted 1 messages into Postgres.\n",
      "Inserted 3 messages into Postgres.\n",
      "Inserted 2 messages into Postgres.\n",
      "Inserted 2 messages into Postgres.\n",
      "Inserted 2 messages into Postgres.\n",
      "Error processing message: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"fact_message_pkey\"\n",
      "DETAIL:  Key (message_id)=(msg_001) already exists.\n",
      "\n",
      "[SQL: INSERT INTO fact_message (message_id, room_id, room_created_at, channel, customer_id, customer_name, phone, sender_type, message_text, message_date) VALUES (%(message_id__0)s, %(room_id__0)s, %(room_created_at__0)s, %(channel__0)s, %(customer_id__0)s ... 584 characters truncated ... s, %(customer_name__3)s, %(phone__3)s, %(sender_type__3)s, %(message_text__3)s, %(message_date__3)s)]\n",
      "[parameters: {'channel__0': 'ads', 'customer_id__0': 'cust_001', 'room_id__0': '300001', 'room_created_at__0': '2024-10-22T04:42:30', 'customer_name__0': 'Alice Johnson', 'sender_type__0': 'customer', 'phone__0': '081234567891', 'message_date__0': '2024-10-22T04:42:30', 'message_text__0': \"Hi! I'm interested in swimming classes\", 'message_id__0': 'msg_001', 'channel__1': 'ads', 'customer_id__1': 'cust_001', 'room_id__1': '300001', 'room_created_at__1': '2024-10-22T04:42:30', 'customer_name__1': 'Alice Johnson', 'sender_type__1': 'agent', 'phone__1': '081234567891', 'message_date__1': '2024-10-22T04:45:30', 'message_text__1': 'Sure! We have classes available for 3-5 Y.O.', 'message_id__1': 'msg_002', 'channel__2': 'ads', 'customer_id__2': 'cust_001', 'room_id__2': '300001', 'room_created_at__2': '2024-10-22T04:42:30', 'customer_name__2': 'Alice Johnson', 'sender_type__2': 'system', 'phone__2': '081234567891', 'message_date__2': '2024-10-23T10:00:00', 'message_text__2': 'Booking confirmed for 24 Oct', 'message_id__2': 'msg_003', 'channel__3': 'ads', 'customer_id__3': 'cust_001', 'room_id__3': '300001', 'room_created_at__3': '2024-10-22T04:42:30', 'customer_name__3': 'Alice Johnson', 'sender_type__3': 'system', 'phone__3': '081234567891', 'message_date__3': '2024-10-24T08:00:00', 'message_text__3': 'Payment of IDR 500000 confirmed', 'message_id__3': 'msg_004'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error processing message: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"fact_message_pkey\"\n",
      "DETAIL:  Key (message_id)=(msg_005) already exists.\n",
      "\n",
      "[SQL: INSERT INTO fact_message (message_id, room_id, room_created_at, channel, customer_id, customer_name, phone, sender_type, message_text, message_date) VALUES (%(message_id__0)s, %(room_id__0)s, %(room_created_at__0)s, %(channel__0)s, %(customer_id__0)s ... 194 characters truncated ... s, %(customer_name__1)s, %(phone__1)s, %(sender_type__1)s, %(message_text__1)s, %(message_date__1)s)]\n",
      "[parameters: {'channel__0': 'website', 'customer_id__0': 'cust_002', 'room_id__0': '300002', 'room_created_at__0': '2024-10-22T04:47:25', 'customer_name__0': 'Bob Smith', 'sender_type__0': 'customer', 'phone__0': '081234567892', 'message_date__0': '2024-10-22T04:47:25', 'message_text__0': 'Interested in a free trial class', 'message_id__0': 'msg_005', 'channel__1': 'website', 'customer_id__1': 'cust_002', 'room_id__1': '300002', 'room_created_at__1': '2024-10-22T04:47:25', 'customer_name__1': 'Bob Smith', 'sender_type__1': 'agent', 'phone__1': '081234567892', 'message_date__1': '2024-10-22T04:50:00', 'message_text__1': 'We can book you for Friday 25th!', 'message_id__1': 'msg_006'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error processing message: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"fact_message_pkey\"\n",
      "DETAIL:  Key (message_id)=(msg_007) already exists.\n",
      "\n",
      "[SQL: INSERT INTO fact_message (message_id, room_id, room_created_at, channel, customer_id, customer_name, phone, sender_type, message_text, message_date) VALUES (%(message_id)s, %(room_id)s, %(room_created_at)s, %(channel)s, %(customer_id)s, %(customer_name)s, %(phone)s, %(sender_type)s, %(message_text)s, %(message_date)s)]\n",
      "[parameters: {'message_id': 'msg_007', 'room_id': '300003', 'room_created_at': '2024-10-22T04:49:53', 'channel': 'campaign', 'customer_id': 'cust_003', 'customer_name': 'Chloe Davis', 'phone': '081234567893', 'sender_type': 'customer', 'message_text': 'Is there a promo for toddlers?', 'message_date': '2024-10-22T04:49:53'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error processing message: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"fact_message_pkey\"\n",
      "DETAIL:  Key (message_id)=(msg_008) already exists.\n",
      "\n",
      "[SQL: INSERT INTO fact_message (message_id, room_id, room_created_at, channel, customer_id, customer_name, phone, sender_type, message_text, message_date) VALUES (%(message_id__0)s, %(room_id__0)s, %(room_created_at__0)s, %(channel__0)s, %(customer_id__0)s ... 389 characters truncated ... s, %(customer_name__2)s, %(phone__2)s, %(sender_type__2)s, %(message_text__2)s, %(message_date__2)s)]\n",
      "[parameters: {'channel__0': 'organic', 'customer_id__0': 'cust_004', 'room_id__0': '300004', 'room_created_at__0': '2024-10-23T09:15:00', 'customer_name__0': 'Daniela Fern', 'sender_type__0': 'customer', 'phone__0': '081234567894', 'message_date__0': '2024-10-23T09:15:00', 'message_text__0': 'How to register for a trial class?', 'message_id__0': 'msg_008', 'channel__1': 'organic', 'customer_id__1': 'cust_004', 'room_id__1': '300004', 'room_created_at__1': '2024-10-23T09:15:00', 'customer_name__1': 'Daniela Fern', 'sender_type__1': 'agent', 'phone__1': '081234567894', 'message_date__1': '2024-10-23T09:17:00', 'message_text__1': 'You can pick a slot on Saturday morning.', 'message_id__1': 'msg_009', 'channel__2': 'organic', 'customer_id__2': 'cust_004', 'room_id__2': '300004', 'room_created_at__2': '2024-10-23T09:15:00', 'customer_name__2': 'Daniela Fern', 'sender_type__2': 'system', 'phone__2': '081234567894', 'message_date__2': '2024-10-23T11:00:00', 'message_text__2': 'Booking confirmed for 26 Oct', 'message_id__2': 'msg_010'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error processing message: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"fact_message_pkey\"\n",
      "DETAIL:  Key (message_id)=(msg_011) already exists.\n",
      "\n",
      "[SQL: INSERT INTO fact_message (message_id, room_id, room_created_at, channel, customer_id, customer_name, phone, sender_type, message_text, message_date) VALUES (%(message_id__0)s, %(room_id__0)s, %(room_created_at__0)s, %(channel__0)s, %(customer_id__0)s ... 194 characters truncated ... s, %(customer_name__1)s, %(phone__1)s, %(sender_type__1)s, %(message_text__1)s, %(message_date__1)s)]\n",
      "[parameters: {'channel__0': 'direct', 'customer_id__0': 'cust_001', 'room_id__0': '300005', 'room_created_at__0': '2024-10-23T10:30:00', 'customer_name__0': 'Alice Johnson', 'sender_type__0': 'customer', 'phone__0': '081234567891', 'message_date__0': '2024-10-23T10:30:00', 'message_text__0': 'Need class schedule update', 'message_id__0': 'msg_011', 'channel__1': 'direct', 'customer_id__1': 'cust_001', 'room_id__1': '300005', 'room_created_at__1': '2024-10-23T10:30:00', 'customer_name__1': 'Alice Johnson', 'sender_type__1': 'agent', 'phone__1': '081234567891', 'message_date__1': '2024-10-23T10:31:00', 'message_text__1': \"We've added more morning sessions\", 'message_id__1': 'msg_012'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error processing message: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"fact_message_pkey\"\n",
      "DETAIL:  Key (message_id)=(msg_021) already exists.\n",
      "\n",
      "[SQL: INSERT INTO fact_message (message_id, room_id, room_created_at, channel, customer_id, customer_name, phone, sender_type, message_text, message_date) VALUES (%(message_id__0)s, %(room_id__0)s, %(room_created_at__0)s, %(channel__0)s, %(customer_id__0)s ... 194 characters truncated ... s, %(customer_name__1)s, %(phone__1)s, %(sender_type__1)s, %(message_text__1)s, %(message_date__1)s)]\n",
      "[parameters: {'channel__0': 'direct', 'customer_id__0': 'cust_001', 'room_id__0': '300006', 'room_created_at__0': '2024-10-23T10:30:00', 'customer_name__0': 'Alice Johnson', 'sender_type__0': 'customer', 'phone__0': '081234567891', 'message_date__0': '2024-10-23T10:30:00', 'message_text__0': 'Need class schedule update', 'message_id__0': 'msg_021', 'channel__1': 'direct', 'customer_id__1': 'cust_001', 'room_id__1': '300006', 'room_created_at__1': '2024-10-23T10:30:00', 'customer_name__1': 'Alice Johnson', 'sender_type__1': 'agent', 'phone__1': '081234567891', 'message_date__1': '2024-10-23T10:31:00', 'message_text__1': \"We've added more morning sessions\", 'message_id__1': 'msg_022'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "Error processing message: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"fact_message_pkey\"\n",
      "DETAIL:  Key (message_id)=(msg_031) already exists.\n",
      "\n",
      "[SQL: INSERT INTO fact_message (message_id, room_id, room_created_at, channel, customer_id, customer_name, phone, sender_type, message_text, message_date) VALUES (%(message_id__0)s, %(room_id__0)s, %(room_created_at__0)s, %(channel__0)s, %(customer_id__0)s ... 194 characters truncated ... s, %(customer_name__1)s, %(phone__1)s, %(sender_type__1)s, %(message_text__1)s, %(message_date__1)s)]\n",
      "[parameters: {'channel__0': 'direct', 'customer_id__0': 'cust_001', 'room_id__0': '300007', 'room_created_at__0': '2025-10-23T10:30:00', 'customer_name__0': 'Alice Johnson', 'sender_type__0': 'customer', 'phone__0': '081234567891', 'message_date__0': '2024-10-23T10:30:00', 'message_text__0': 'Need class schedule update', 'message_id__0': 'msg_031', 'channel__1': 'direct', 'customer_id__1': 'cust_001', 'room_id__1': '300007', 'room_created_at__1': '2025-10-23T10:30:00', 'customer_name__1': 'Alice Johnson', 'sender_type__1': 'agent', 'phone__1': '081234567891', 'message_date__1': '2024-10-23T10:31:00', 'message_text__1': \"We've added more morning sessions\", 'message_id__1': 'msg_032'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 28\u001b[0m\n\u001b[0;32m     19\u001b[0m consumer \u001b[38;5;241m=\u001b[39m KafkaConsumer(\n\u001b[0;32m     20\u001b[0m     os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTOPIC_NAME\u001b[39m\u001b[38;5;124m\"\u001b[39m),  \u001b[38;5;66;03m# The topic to consume messages from\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     bootstrap_servers\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKAFKA_BROKER\u001b[39m\u001b[38;5;124m\"\u001b[39m),  \u001b[38;5;66;03m# List of Kafka brokers to connect to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     value_deserializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Deserialize message values from bytes to UTF-8 strings\u001b[39;00m\n\u001b[0;32m     25\u001b[0m )\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Consume messages with error handling for non-JSON messages\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconsumer\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\kafka\\consumer\\group.py:1203\u001b[0m, in \u001b[0;36mKafkaConsumer.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_v1()\n\u001b[0;32m   1202\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\kafka\\consumer\\group.py:1211\u001b[0m, in \u001b[0;36mKafkaConsumer.next_v2\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_generator_v2()\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator)\n\u001b[0;32m   1212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m   1213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\kafka\\consumer\\group.py:1126\u001b[0m, in \u001b[0;36mKafkaConsumer._message_generator_v2\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_message_generator_v2\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1125\u001b[0m     timeout_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consumer_timeout \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mtime())\n\u001b[1;32m-> 1126\u001b[0m     record_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1127\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tp, records \u001b[38;5;129;01min\u001b[39;00m record_map\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   1128\u001b[0m         \u001b[38;5;66;03m# Generators are stateful, and it is possible that the tp / records\u001b[39;00m\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;66;03m# here may become stale during iteration -- i.e., we seek to a\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m         \u001b[38;5;66;03m# different offset, pause consumption, or lose assignment.\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m records:\n\u001b[0;32m   1132\u001b[0m             \u001b[38;5;66;03m# is_fetchable(tp) should handle assignment changes and offset\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m             \u001b[38;5;66;03m# resets; for all other changes (e.g., seeks) we'll rely on the\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m             \u001b[38;5;66;03m# outer function destroying the existing iterator/generator\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m             \u001b[38;5;66;03m# via self._iterator = None\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\kafka\\consumer\\group.py:663\u001b[0m, in \u001b[0;36mKafkaConsumer.poll\u001b[1;34m(self, timeout_ms, max_records, update_offsets)\u001b[0m\n\u001b[0;32m    661\u001b[0m remaining \u001b[38;5;241m=\u001b[39m timeout_ms\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closed:\n\u001b[1;32m--> 663\u001b[0m     records \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_records\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdate_offsets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    664\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m records:\n\u001b[0;32m    665\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m records\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\kafka\\consumer\\group.py:712\u001b[0m, in \u001b[0;36mKafkaConsumer._poll_once\u001b[1;34m(self, timeout_ms, max_records, update_offsets)\u001b[0m\n\u001b[0;32m    709\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mpoll(timeout_ms\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    711\u001b[0m timeout_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(timeout_ms, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coordinator\u001b[38;5;241m.\u001b[39mtime_to_next_poll() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m--> 712\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# after the long poll, we should check whether the group needs to rebalance\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# prior to returning data so that the group can stabilize faster\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coordinator\u001b[38;5;241m.\u001b[39mneed_rejoin():\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\kafka\\client_async.py:601\u001b[0m, in \u001b[0;36mKafkaClient.poll\u001b[1;34m(self, timeout_ms, future)\u001b[0m\n\u001b[0;32m    598\u001b[0m             timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(timeout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretry_backoff_ms\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    599\u001b[0m         timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, timeout)  \u001b[38;5;66;03m# avoid negative timeouts\u001b[39;00m\n\u001b[1;32m--> 601\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;66;03m# called without the lock to avoid deadlock potential\u001b[39;00m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# if handlers need to acquire locks\u001b[39;00m\n\u001b[0;32m    605\u001b[0m responses\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_pending_completed_requests())\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\kafka\\client_async.py:633\u001b[0m, in \u001b[0;36mKafkaClient._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_register_send_sockets()\n\u001b[0;32m    632\u001b[0m start_select \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 633\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m end_select \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sensors:\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\selectors.py:323\u001b[0m, in \u001b[0;36mSelectSelector.select\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    321\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 323\u001b[0m     r, w, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_readers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_writers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\selectors.py:314\u001b[0m, in \u001b[0;36mSelectSelector._select\u001b[1;34m(self, r, w, _, timeout)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_select\u001b[39m(\u001b[38;5;28mself\u001b[39m, r, w, _, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 314\u001b[0m     r, w, x \u001b[38;5;241m=\u001b[39m select\u001b[38;5;241m.\u001b[39mselect(r, w, w, timeout)\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r, w \u001b[38;5;241m+\u001b[39m x, []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from kafka import KafkaConsumer\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# PostgreSQL connection\n",
    "POSTGRES_USER = os.getenv(\"POSTGRES_USER\")\n",
    "POSTGRES_PASSWORD = os.getenv(\"POSTGRES_PASSWORD\")\n",
    "POSTGRES_HOST = os.getenv(\"POSTGRES_HOST\", \"localhost\")\n",
    "POSTGRES_PORT = os.getenv(\"POSTGRES_PORT\", \"5435\")\n",
    "POSTGRES_DB = os.getenv(\"POSTGRES_DB\")\n",
    "\n",
    "# SQLAlchemy engine\n",
    "engine = create_engine(f'postgresql://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DB}')\n",
    "\n",
    "\n",
    "# Define Kafka consumer\n",
    "consumer = KafkaConsumer(\n",
    "    os.getenv(\"TOPIC_NAME\"),  # The topic to consume messages from\n",
    "    bootstrap_servers=os.getenv(\"KAFKA_BROKER\"),  # List of Kafka brokers to connect to\n",
    "    auto_offset_reset='earliest',  # Where to start reading messages when no offset is stored ('earliest' to read from the beginning)\n",
    "    enable_auto_commit=True,  # Automatically commit offsets after consuming messages\n",
    "    value_deserializer=lambda x: x.decode('utf-8') if x else None  # Deserialize message values from bytes to UTF-8 strings\n",
    ")\n",
    "\n",
    "# Consume messages with error handling for non-JSON messages\n",
    "for msg in consumer:\n",
    "    try:\n",
    "        data = json.loads(msg.value)\n",
    "\n",
    "        room_id = data.get('room_id')\n",
    "        room_created_at = data.get('room_created_at')\n",
    "        channel = data.get('channel')\n",
    "        customer = data.get('customer', {})\n",
    "        messages = data.get('messages', [])\n",
    "\n",
    "        rows = []\n",
    "        for message in messages:\n",
    "            rows.append({\n",
    "                \"message_id\": message.get(\"message_id\"),\n",
    "                \"room_id\": room_id,\n",
    "                \"room_created_at\": room_created_at,\n",
    "                \"channel\": channel,\n",
    "                \"customer_id\": customer.get(\"customer_id\"),\n",
    "                \"customer_name\": customer.get(\"customer_name\"),\n",
    "                \"phone\": customer.get(\"phone\"),\n",
    "                \"sender_type\": message.get(\"sender_type\"),\n",
    "                \"message_text\": message.get(\"message_text\"),\n",
    "                \"message_date\": message.get(\"message_date\")\n",
    "            })\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "\n",
    "        # Insert into Postgres\n",
    "        df.to_sql(\"fact_message\", engine, if_exists='append', index=False)\n",
    "\n",
    "        print(f\"Inserted {len(df)} messages into Postgres.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing message: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feb4159",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 22:40:44,352 - INFO - Database connection established successfully\n",
      "2025-06-04 22:40:44,352 - INFO - <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]\n",
      "2025-06-04 22:40:44,364 - INFO - Probing node bootstrap-0 broker version\n",
      "2025-06-04 22:40:44,364 - INFO - <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.\n",
      "2025-06-04 22:40:44,468 - INFO - Broker version identified as 2.6.0\n",
      "2025-06-04 22:40:44,468 - INFO - Set configuration api_version=(2, 6, 0) to skip auto check_version requests on startup\n",
      "2025-06-04 22:40:44,468 - WARNING - group_id is None: disabling auto-commit.\n",
      "2025-06-04 22:40:44,468 - INFO - Updating subscribed topics to: ('test-topic',)\n",
      "2025-06-04 22:40:44,468 - INFO - Kafka consumer created for topic: test-topic\n",
      "2025-06-04 22:40:44,468 - INFO - Starting Kafka message consumer...\n",
      "2025-06-04 22:40:44,479 - INFO - Updated partition assignment: [TopicPartition(topic='test-topic', partition=0)]\n",
      "2025-06-04 22:40:44,479 - INFO - <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]\n",
      "2025-06-04 22:40:44,479 - INFO - <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: Connection complete.\n",
      "2025-06-04 22:40:44,479 - INFO - <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. \n",
      "2025-06-04 22:40:44,602 - INFO - Successfully inserted 4 messages into database\n",
      "2025-06-04 22:40:44,618 - INFO - Successfully inserted 2 messages into database\n",
      "2025-06-04 22:40:44,628 - INFO - Successfully inserted 1 messages into database\n",
      "2025-06-04 22:40:44,636 - INFO - Successfully inserted 3 messages into database\n",
      "2025-06-04 22:40:44,660 - INFO - Successfully inserted 2 messages into database\n",
      "2025-06-04 22:40:44,701 - INFO - Successfully inserted 2 messages into database\n",
      "2025-06-04 22:40:44,718 - INFO - Successfully inserted 2 messages into database\n",
      "2025-06-04 22:40:44,731 - ERROR - Database insertion failed: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"fact_message_pkey\"\n",
      "DETAIL:  Key (message_id)=(msg_001) already exists.\n",
      "\n",
      "[SQL: INSERT INTO fact_message (message_id, room_id, room_created_at, channel, customer_id, customer_name, phone, sender_type, message_text, message_date) VALUES (%(message_id__0)s, %(room_id__0)s, %(room_created_at__0)s, %(channel__0)s, %(customer_id__0)s ... 584 characters truncated ... s, %(customer_name__3)s, %(phone__3)s, %(sender_type__3)s, %(message_text__3)s, %(message_date__3)s)]\n",
      "[parameters: {'channel__0': 'ads', 'customer_id__0': 'cust_001', 'room_id__0': '300001', 'room_created_at__0': '2024-10-22T04:42:30', 'customer_name__0': 'Alice Johnson', 'sender_type__0': 'customer', 'phone__0': '081234567891', 'message_date__0': '2024-10-22T04:42:30', 'message_text__0': \"Hi! I'm interested in swimming classes\", 'message_id__0': 'msg_001', 'channel__1': 'ads', 'customer_id__1': 'cust_001', 'room_id__1': '300001', 'room_created_at__1': '2024-10-22T04:42:30', 'customer_name__1': 'Alice Johnson', 'sender_type__1': 'agent', 'phone__1': '081234567891', 'message_date__1': '2024-10-22T04:45:30', 'message_text__1': 'Sure! We have classes available for 3-5 Y.O.', 'message_id__1': 'msg_002', 'channel__2': 'ads', 'customer_id__2': 'cust_001', 'room_id__2': '300001', 'room_created_at__2': '2024-10-22T04:42:30', 'customer_name__2': 'Alice Johnson', 'sender_type__2': 'system', 'phone__2': '081234567891', 'message_date__2': '2024-10-23T10:00:00', 'message_text__2': 'Booking confirmed for 24 Oct', 'message_id__2': 'msg_003', 'channel__3': 'ads', 'customer_id__3': 'cust_001', 'room_id__3': '300001', 'room_created_at__3': '2024-10-22T04:42:30', 'customer_name__3': 'Alice Johnson', 'sender_type__3': 'system', 'phone__3': '081234567891', 'message_date__3': '2024-10-24T08:00:00', 'message_text__3': 'Payment of IDR 500000 confirmed', 'message_id__3': 'msg_004'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "2025-06-04 22:40:44,732 - WARNING - Failed to process message, continuing...\n",
      "2025-06-04 22:40:44,742 - ERROR - Database insertion failed: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"fact_message_pkey\"\n",
      "DETAIL:  Key (message_id)=(msg_005) already exists.\n",
      "\n",
      "[SQL: INSERT INTO fact_message (message_id, room_id, room_created_at, channel, customer_id, customer_name, phone, sender_type, message_text, message_date) VALUES (%(message_id__0)s, %(room_id__0)s, %(room_created_at__0)s, %(channel__0)s, %(customer_id__0)s ... 194 characters truncated ... s, %(customer_name__1)s, %(phone__1)s, %(sender_type__1)s, %(message_text__1)s, %(message_date__1)s)]\n",
      "[parameters: {'channel__0': 'website', 'customer_id__0': 'cust_002', 'room_id__0': '300002', 'room_created_at__0': '2024-10-22T04:47:25', 'customer_name__0': 'Bob Smith', 'sender_type__0': 'customer', 'phone__0': '081234567892', 'message_date__0': '2024-10-22T04:47:25', 'message_text__0': 'Interested in a free trial class', 'message_id__0': 'msg_005', 'channel__1': 'website', 'customer_id__1': 'cust_002', 'room_id__1': '300002', 'room_created_at__1': '2024-10-22T04:47:25', 'customer_name__1': 'Bob Smith', 'sender_type__1': 'agent', 'phone__1': '081234567892', 'message_date__1': '2024-10-22T04:50:00', 'message_text__1': 'We can book you for Friday 25th!', 'message_id__1': 'msg_006'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "2025-06-04 22:40:44,743 - WARNING - Failed to process message, continuing...\n",
      "2025-06-04 22:40:44,752 - ERROR - Database insertion failed: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"fact_message_pkey\"\n",
      "DETAIL:  Key (message_id)=(msg_007) already exists.\n",
      "\n",
      "[SQL: INSERT INTO fact_message (message_id, room_id, room_created_at, channel, customer_id, customer_name, phone, sender_type, message_text, message_date) VALUES (%(message_id)s, %(room_id)s, %(room_created_at)s, %(channel)s, %(customer_id)s, %(customer_name)s, %(phone)s, %(sender_type)s, %(message_text)s, %(message_date)s)]\n",
      "[parameters: {'message_id': 'msg_007', 'room_id': '300003', 'room_created_at': '2024-10-22T04:49:53', 'channel': 'campaign', 'customer_id': 'cust_003', 'customer_name': 'Chloe Davis', 'phone': '081234567893', 'sender_type': 'customer', 'message_text': 'Is there a promo for toddlers?', 'message_date': '2024-10-22T04:49:53'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "2025-06-04 22:40:44,754 - WARNING - Failed to process message, continuing...\n",
      "2025-06-04 22:40:44,764 - ERROR - Database insertion failed: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"fact_message_pkey\"\n",
      "DETAIL:  Key (message_id)=(msg_008) already exists.\n",
      "\n",
      "[SQL: INSERT INTO fact_message (message_id, room_id, room_created_at, channel, customer_id, customer_name, phone, sender_type, message_text, message_date) VALUES (%(message_id__0)s, %(room_id__0)s, %(room_created_at__0)s, %(channel__0)s, %(customer_id__0)s ... 389 characters truncated ... s, %(customer_name__2)s, %(phone__2)s, %(sender_type__2)s, %(message_text__2)s, %(message_date__2)s)]\n",
      "[parameters: {'channel__0': 'organic', 'customer_id__0': 'cust_004', 'room_id__0': '300004', 'room_created_at__0': '2024-10-23T09:15:00', 'customer_name__0': 'Daniela Fern', 'sender_type__0': 'customer', 'phone__0': '081234567894', 'message_date__0': '2024-10-23T09:15:00', 'message_text__0': 'How to register for a trial class?', 'message_id__0': 'msg_008', 'channel__1': 'organic', 'customer_id__1': 'cust_004', 'room_id__1': '300004', 'room_created_at__1': '2024-10-23T09:15:00', 'customer_name__1': 'Daniela Fern', 'sender_type__1': 'agent', 'phone__1': '081234567894', 'message_date__1': '2024-10-23T09:17:00', 'message_text__1': 'You can pick a slot on Saturday morning.', 'message_id__1': 'msg_009', 'channel__2': 'organic', 'customer_id__2': 'cust_004', 'room_id__2': '300004', 'room_created_at__2': '2024-10-23T09:15:00', 'customer_name__2': 'Daniela Fern', 'sender_type__2': 'system', 'phone__2': '081234567894', 'message_date__2': '2024-10-23T11:00:00', 'message_text__2': 'Booking confirmed for 26 Oct', 'message_id__2': 'msg_010'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "2025-06-04 22:40:44,765 - WARNING - Failed to process message, continuing...\n",
      "2025-06-04 22:40:44,775 - ERROR - Database insertion failed: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"fact_message_pkey\"\n",
      "DETAIL:  Key (message_id)=(msg_011) already exists.\n",
      "\n",
      "[SQL: INSERT INTO fact_message (message_id, room_id, room_created_at, channel, customer_id, customer_name, phone, sender_type, message_text, message_date) VALUES (%(message_id__0)s, %(room_id__0)s, %(room_created_at__0)s, %(channel__0)s, %(customer_id__0)s ... 194 characters truncated ... s, %(customer_name__1)s, %(phone__1)s, %(sender_type__1)s, %(message_text__1)s, %(message_date__1)s)]\n",
      "[parameters: {'channel__0': 'direct', 'customer_id__0': 'cust_001', 'room_id__0': '300005', 'room_created_at__0': '2024-10-23T10:30:00', 'customer_name__0': 'Alice Johnson', 'sender_type__0': 'customer', 'phone__0': '081234567891', 'message_date__0': '2024-10-23T10:30:00', 'message_text__0': 'Need class schedule update', 'message_id__0': 'msg_011', 'channel__1': 'direct', 'customer_id__1': 'cust_001', 'room_id__1': '300005', 'room_created_at__1': '2024-10-23T10:30:00', 'customer_name__1': 'Alice Johnson', 'sender_type__1': 'agent', 'phone__1': '081234567891', 'message_date__1': '2024-10-23T10:31:00', 'message_text__1': \"We've added more morning sessions\", 'message_id__1': 'msg_012'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "2025-06-04 22:40:44,776 - WARNING - Failed to process message, continuing...\n",
      "2025-06-04 22:40:44,785 - ERROR - Database insertion failed: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"fact_message_pkey\"\n",
      "DETAIL:  Key (message_id)=(msg_021) already exists.\n",
      "\n",
      "[SQL: INSERT INTO fact_message (message_id, room_id, room_created_at, channel, customer_id, customer_name, phone, sender_type, message_text, message_date) VALUES (%(message_id__0)s, %(room_id__0)s, %(room_created_at__0)s, %(channel__0)s, %(customer_id__0)s ... 194 characters truncated ... s, %(customer_name__1)s, %(phone__1)s, %(sender_type__1)s, %(message_text__1)s, %(message_date__1)s)]\n",
      "[parameters: {'channel__0': 'direct', 'customer_id__0': 'cust_001', 'room_id__0': '300006', 'room_created_at__0': '2024-10-23T10:30:00', 'customer_name__0': 'Alice Johnson', 'sender_type__0': 'customer', 'phone__0': '081234567891', 'message_date__0': '2024-10-23T10:30:00', 'message_text__0': 'Need class schedule update', 'message_id__0': 'msg_021', 'channel__1': 'direct', 'customer_id__1': 'cust_001', 'room_id__1': '300006', 'room_created_at__1': '2024-10-23T10:30:00', 'customer_name__1': 'Alice Johnson', 'sender_type__1': 'agent', 'phone__1': '081234567891', 'message_date__1': '2024-10-23T10:31:00', 'message_text__1': \"We've added more morning sessions\", 'message_id__1': 'msg_022'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "2025-06-04 22:40:44,786 - WARNING - Failed to process message, continuing...\n",
      "2025-06-04 22:40:44,797 - ERROR - Database insertion failed: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"fact_message_pkey\"\n",
      "DETAIL:  Key (message_id)=(msg_031) already exists.\n",
      "\n",
      "[SQL: INSERT INTO fact_message (message_id, room_id, room_created_at, channel, customer_id, customer_name, phone, sender_type, message_text, message_date) VALUES (%(message_id__0)s, %(room_id__0)s, %(room_created_at__0)s, %(channel__0)s, %(customer_id__0)s ... 194 characters truncated ... s, %(customer_name__1)s, %(phone__1)s, %(sender_type__1)s, %(message_text__1)s, %(message_date__1)s)]\n",
      "[parameters: {'channel__0': 'direct', 'customer_id__0': 'cust_001', 'room_id__0': '300007', 'room_created_at__0': '2025-10-23T10:30:00', 'customer_name__0': 'Alice Johnson', 'sender_type__0': 'customer', 'phone__0': '081234567891', 'message_date__0': '2024-10-23T10:30:00', 'message_text__0': 'Need class schedule update', 'message_id__0': 'msg_031', 'channel__1': 'direct', 'customer_id__1': 'cust_001', 'room_id__1': '300007', 'room_created_at__1': '2025-10-23T10:30:00', 'customer_name__1': 'Alice Johnson', 'sender_type__1': 'agent', 'phone__1': '081234567891', 'message_date__1': '2024-10-23T10:31:00', 'message_text__1': \"We've added more morning sessions\", 'message_id__1': 'msg_032'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "2025-06-04 22:40:44,798 - WARNING - Failed to process message, continuing...\n",
      "2025-06-04 22:40:45,809 - INFO - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>: Closing connection. \n",
      "2025-06-04 22:40:45,810 - ERROR - Fetch to node 1001 failed: Cancelled: <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv6 ('::1', 9092, 0, 0)]>\n",
      "2025-06-04 22:40:45,810 - INFO - Kafka consumer closed\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from kafka import KafkaConsumer\n",
    "from minio import Minio\n",
    "\n",
    "\n",
    "def setup_logging():\n",
    "    \"\"\"Configure logging for the application.\"\"\"\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "    )\n",
    "    return logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def create_minio_client():\n",
    "    \"\"\"Create MinIO client with environment variables.\"\"\"\n",
    "    access_key = os.getenv(\"MINIO_ACCESS_KEY\")\n",
    "    secret_key = os.getenv(\"MINIO_SECRET_KEY\")\n",
    "    endpoint = os.getenv(\"MINIO_ENDPOINT\", \"localhost:9000\")\n",
    "    \n",
    "    if not access_key or not secret_key:\n",
    "        raise ValueError(\"MINIO_ACCESS_KEY and MINIO_SECRET_KEY are required\")\n",
    "    \n",
    "    return Minio(\n",
    "        endpoint=endpoint,\n",
    "        access_key=access_key,\n",
    "        secret_key=secret_key,\n",
    "        secure=False\n",
    "    )\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the Kafka consumer.\"\"\"\n",
    "    logger = setup_logging()\n",
    "    \n",
    "    try:\n",
    "        # Create MinIO client\n",
    "        client = create_minio_client()\n",
    "        bucket_name = os.getenv(\"MINIO_BUCKET\", \"kafka-messages\")\n",
    "        \n",
    "        # Ensure bucket exists\n",
    "        if not client.bucket_exists(bucket_name):\n",
    "            client.make_bucket(bucket_name)\n",
    "            logger.info(f\"Created bucket: {bucket_name}\")\n",
    "        \n",
    "        # Create Kafka consumer\n",
    "        consumer = KafkaConsumer(\n",
    "            'test-topic',\n",
    "            bootstrap_servers=['localhost:9092'],\n",
    "            auto_offset_reset='earliest',\n",
    "            enable_auto_commit=True,\n",
    "            value_deserializer=lambda x: x.decode('utf-8') if x else None\n",
    "        )\n",
    "        \n",
    "        logger.info(\"Starting Kafka message consumer...\")\n",
    "        \n",
    "        # Simple consumer loop\n",
    "        for count, message in enumerate(consumer):\n",
    "            try:\n",
    "                # Create object name\n",
    "                object_name = f\"messages/message_{count}.json\"\n",
    "                \n",
    "                # Upload message to MinIO\n",
    "                message_data = json.dumps(json.loads(message.value), indent=2)\n",
    "                client.put_object(\n",
    "                    bucket_name,\n",
    "                    object_name,\n",
    "                    data=message_data.encode('utf-8'),\n",
    "                    length=len(message_data.encode('utf-8')),\n",
    "                    content_type='application/json'\n",
    "                )\n",
    "                \n",
    "                logger.info(f\"Uploaded message {count} to {bucket_name}/{object_name}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing message {count}: {e}\")\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        logger.info(\"Consumer interrupted by user\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fatal error: {e}\")\n",
    "        sys.exit(1)\n",
    "    finally:\n",
    "        try:\n",
    "            consumer.close()\n",
    "            logger.info(\"Kafka consumer closed\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd94f216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28471695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d84888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36432305",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
